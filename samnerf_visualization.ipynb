{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    \n",
    "\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"default\"\n",
    "sam_checkpoint = '/disk1/yichen/sam_vit_h_4b8939.pth'\n",
    "device = 'cuda:0'\n",
    "image_file = '/disk1/yichen/lerf/debug/sam_feature_1.png'\n",
    "image = cv2.imread(image_file)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "sam_feature = np.load('/disk1/yichen/lerf/debug/sam_feature_1.npy')\n",
    "sam_feature = sam_feature.transpose(2,0,1)\n",
    "\n",
    "# contrastive_feature = np.load('/disk1/yichen/lerf/debug/sam_feature.npy')\n",
    "# contrastive_feature = contrastive_feature.transpose(2,0,1)\n",
    "\n",
    "input_point = np.array([[130, 230]])\n",
    "input_label = np.array([1])\n",
    "print(sam_feature.shape)\n",
    "# print(contrastive_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_func(feature_q, support):\n",
    "    similar_type = 'l2_exp'\n",
    "    if similar_type == 'cos':\n",
    "        feature_q = feature_q / feature_q.norm(dim=-1, keepdim=True)\n",
    "        support = support / support.norm(dim=-1, keepdim=True)\n",
    "        pred_1 = F.cosine_similarity(feature_q, support, dim=1)\n",
    "    elif similar_type == 'l2':\n",
    "        pred_1 = torch.sum((flatten_feature - support_ray)**2, dim=-1)\n",
    "        pred_1 = torch.pow(pred_1, 0.5) / flatten_feature.norm(dim=-1, keepdim=False)\n",
    "    elif similar_type == 'l2_exp':\n",
    "        pred_1 = torch.exp(-20 * torch.sum((flatten_feature - support_ray)**2, -1))\n",
    "    return pred_1\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    sam_feature_dim = contrastive_feature.shape\n",
    "    flatten_feature = contrastive_feature.reshape([sam_feature_dim[0], -1])\n",
    "    flatten_feature = torch.from_numpy(flatten_feature)\n",
    "    flatten_feature = flatten_feature.permute(1,0)\n",
    "    flatten_feature = flatten_feature\n",
    "    flatten_feature_norm = flatten_feature.norm(dim=-1, keepdim=False)\n",
    "\n",
    "\n",
    "    support_ray_index = input_point[0][0] + input_point[0][1] * sam_feature_dim[2]\n",
    "    # support_ray_index = torch.randint(0,  flatten_feature.size(0), (1,))\n",
    "    support_ray = flatten_feature[support_ray_index]\n",
    "\n",
    "    # self_support_mask = self_support(flatten_feature, support_ray)\n",
    "    # self_support_mask = F.cosine_similarity(flatten_feature, support_ray, dim=1)\n",
    "\n",
    "    self_support_mask = similar_func(flatten_feature, support_ray)\n",
    "    \n",
    "    self_support_mask = self_support_mask.reshape(sam_feature_dim[1:])\n",
    "    self_support_mask = (self_support_mask > 0.005)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    show_mask(self_support_mask, plt.gca())\n",
    "    show_points(input_point, input_label, plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_sam_feature(feature):\n",
    "    feature_max_dim = np.max(feature.shape[1:])\n",
    "    padded_feature = np.pad(feature, ((0, 0), (0, feature_max_dim - feature.shape[1]), \n",
    "                                      (0, feature_max_dim - feature.shape[2])), mode='constant')\n",
    "    \n",
    "    target_res = 64\n",
    "    factor = feature_max_dim // target_res\n",
    "    offset = factor // 2 - 1\n",
    "\n",
    "    downsampled_feature = padded_feature[:, offset::factor, offset::factor]\n",
    "    print(downsampled_feature.shape)\n",
    "    return downsampled_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "predictor = SamPredictor(sam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.set_image(image)\n",
    "\n",
    "downsampled_feature = downsample_sam_feature(sam_feature)\n",
    "torch_feature = torch.from_numpy(downsampled_feature).float().to(device)\n",
    "torch_feature = torch_feature.unsqueeze(0)\n",
    "predictor.features = torch_feature\n",
    "# predictor.set_torch_feature(sam_feature)\n",
    "\n",
    "masks, scores, logits = predictor.predict(\n",
    "    point_coords=input_point,\n",
    "    point_labels=input_label,\n",
    "    multimask_output=True,\n",
    ")\n",
    "\n",
    "for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    show_mask(mask, plt.gca())\n",
    "    show_points(input_point, input_label, plt.gca())\n",
    "    plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
